# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pTpoApo_7nPuwoYH8klHIVQtS5mFXV_m
"""

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from imblearn.over_sampling import RandomOverSampler
import nltk
import pandas as pd

# Download stopwords for Bahasa Indonesia
nltk.download('stopwords')
stop_words_id = set(stopwords.words('indonesian'))

# Read the dataset
df = pd.read_csv('resep.csv')

# Take a sample of 200 rows from the dataset
df_sample = df.sample(n=1000, random_state=42)

# Handle NaN values in the 'Ingredients' and 'Steps' columns
df_sample['Ingredients'] = df_sample['Ingredients'].fillna('')
df_sample['Steps'] = df_sample['Steps'].fillna('')

# Tokenization and text preprocessing
vectorizer = TfidfVectorizer(tokenizer=word_tokenize, stop_words=list(stop_words_id))
X_sample = vectorizer.fit_transform(df_sample['Ingredients'] + ' ' + df_sample['Steps'])
y_sample = df_sample['Loves']

# Handling Imbalanced Classes using RandomOverSampler
oversampler = RandomOverSampler(random_state=42)
X_resampled_sample, y_resampled_sample = oversampler.fit_resample(X_sample, y_sample)

# Split the resampled data into training and testing sets
X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(
    X_resampled_sample, y_resampled_sample, test_size=0.2, random_state=42
)

# Define the parameter grid for GridSearchCV
param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [None, 10],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

# Initialize Random Forest model
rf_model = RandomForestClassifier(random_state=42)

# Initialize GridSearchCV
grid_search = GridSearchCV(
    estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1
)

# Perform Grid Search to find the best hyperparameters
grid_search.fit(X_train_sample, y_train_sample)

# Get the best hyperparameters
best_params = grid_search.best_params_

# Initialize and train the Random Forest model with the best hyperparameters
best_rf_model = RandomForestClassifier(
    n_estimators=best_params['n_estimators'],
    max_depth=best_params['max_depth'],
    min_samples_split=best_params['min_samples_split'],
    min_samples_leaf=best_params['min_samples_leaf'],
    random_state=42,
)
best_rf_model.fit(X_train_sample, y_train_sample)

# Make predictions on the test data
y_pred_sample = best_rf_model.predict(X_test_sample)

# Evaluate the model
accuracy_sample = accuracy_score(y_test_sample, y_pred_sample)
classification_report_result_sample = classification_report(
    y_test_sample, y_pred_sample
)

print(f'Best Hyperparameters: {best_params}')
print(f'Accuracy on Sampled Data: {accuracy_sample}')
print('Classification Report on Sampled Data:')
print(classification_report_result_sample)

from sklearn.metrics.pairwise import cosine_similarity

# Fungsi untuk melakukan prediksi berdasarkan bahan
def predict_recipe(ingredients, vectorizer, model, df):
    # Transformasi bahan ke dalam format yang sama dengan data latih
    input_text = ' '.join(ingredients)
    input_vector = vectorizer.transform([input_text])

    # Lakukan prediksi
    prediction = model.predict(input_vector)[0]

    # Temukan resep dengan bahan paling mirip
    ingredient_vectors = vectorizer.transform(df['Ingredients'] + ' ' + df['Steps'])
    similarity_scores = cosine_similarity(input_vector, ingredient_vectors).flatten()
    most_similar_recipe_index = similarity_scores.argmax()
    most_similar_recipe = df.iloc[most_similar_recipe_index]

    # Tampilkan hasil
    print(f"Title: {most_similar_recipe['Title']}")
    print(f"Ingredients: {most_similar_recipe['Ingredients']}")
    print(f"Steps: {most_similar_recipe['Steps']}")

# Menggantikan nilai NaN dengan string kosong pada kolom 'Ingredients' dan 'Steps'
df['Ingredients'] = df['Ingredients'].fillna('')
df['Steps'] = df['Steps'].fillna('')

# Meminta pengguna untuk memasukkan bahan
user_input = input("Masukkan bahan makanan (pisahkan dengan koma): ")
user_ingredients = [ingredient.strip() for ingredient in user_input.split(',')]

# Memastikan bahwa setiap elemen dalam kolom 'Ingredients' dan 'Steps' bukan NaN
df['Ingredients'] = df['Ingredients'].apply(lambda x: '' if pd.isna(x) else x)
df['Steps'] = df['Steps'].apply(lambda x: '' if pd.isna(x) else x)

# Lakukan prediksi dengan bahan yang dimasukkan pengguna
predict_recipe(user_ingredients, vectorizer, best_rf_model, df)

"""## NEW CODE URUT SIMILIARTY"""

import nltk
nltk.download('punkt')

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from imblearn.over_sampling import RandomOverSampler
import nltk

# Download stopwords for Bahasa Indonesia
nltk.download('stopwords')
stop_words_id = set(stopwords.words('indonesian'))

# Read the dataset
df = pd.read_excel('dataset resep.xlsx')

# Adjust sample size based on the actual number of rows in your DataFrame
sample_size = min(160, len(df))

# Take a sample of rows from the dataset
df_sample = df.sample(n=sample_size, random_state=42, replace=True)

# Handle NaN values in the 'Ingredients' and 'Steps' columns
df_sample['Ingredients'] = df_sample['Ingredients'].fillna('')
df_sample['Steps'] = df_sample['Steps'].fillna('')

# Tokenization and text preprocessing
vectorizer = TfidfVectorizer(tokenizer=word_tokenize, stop_words=list(stop_words_id))
X_sample = vectorizer.fit_transform(df_sample['Ingredients'] + ' ' + df_sample['Steps'])
y_sample = df_sample['Loves']

# Handling Imbalanced Classes using RandomOverSampler
oversampler = RandomOverSampler(random_state=42)
X_resampled_sample, y_resampled_sample = oversampler.fit_resample(X_sample, y_sample)

# Split the resampled data into training and testing sets
X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(
    X_resampled_sample, y_resampled_sample, test_size=0.2, random_state=42
)

# Define the parameter grid for GridSearchCV
param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [None, 10],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

# Initialize Random Forest model
rf_model = RandomForestClassifier(random_state=42)

# Initialize GridSearchCV with parallel processing
grid_search = GridSearchCV(
    estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1
)

# Perform Grid Search to find the best hyperparameters
grid_search.fit(X_train_sample, y_train_sample)

# Get the best hyperparameters
best_params = grid_search.best_params_

# Initialize and train the Random Forest model with the best hyperparameters
best_rf_model = RandomForestClassifier(
    n_estimators=best_params['n_estimators'],
    max_depth=best_params['max_depth'],
    min_samples_split=best_params['min_samples_split'],
    min_samples_leaf=best_params['min_samples_leaf'],
    random_state=42,
)
best_rf_model.fit(X_train_sample, y_train_sample)

# Make predictions on the test data
y_pred_sample = best_rf_model.predict(X_test_sample)

# Evaluate the model using accuracy, precision, recall, and F1-score
accuracy_sample = accuracy_score(y_test_sample, y_pred_sample)

# Remove target_names parameter or set it to None
classification_report_result_sample = classification_report(
    y_test_sample, y_pred_sample, target_names=None
)

# Print results
print(f'Best Hyperparameters: {best_params}')
print(f'Accuracy on Sampled Data: {accuracy_sample}')
print('Classification Report on Sampled Data:')
print(classification_report_result_sample)

from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

# Fungsi untuk melakukan prediksi 5 resep berdasarkan bahan dan rasa
def predict_top_5_recipes(ingredients, flavors, vectorizer, model, df):
    # Transformasi bahan dan rasa ke dalam format yang sama dengan data latih
    input_text = ' '.join(ingredients + flavors)
    input_vector = vectorizer.transform([input_text])

    # Lakukan prediksi
    prediction = model.predict(input_vector)[0]

    # Temukan resep dengan bahan paling mirip
    ingredient_vectors = vectorizer.transform(df['Ingredients'] + ' ' + df['Steps'])
    similarity_scores = cosine_similarity(input_vector, ingredient_vectors).flatten()

    # Berikan tambahan point untuk setiap resep yang mengandung rasa yang diinginkan
    for flavor in flavors:
        similarity_scores += df['Ingredients'].apply(lambda x: flavor.lower() in x.lower()).astype(int)

    # Temukan 5 resep paling mirip berdasarkan similarity
    top_5_indices = similarity_scores.argsort()[-5:][::-1]
    top_5_recipes = df.iloc[top_5_indices]

    # Tampilkan pertanyaan input
    print(f"Bahan yang Dimasukkan: {', '.join(ingredients)}")
    print(f"Rasa yang Diinginkan: {', '.join(flavors)}")

    # Tampilkan hasil
    print("Top 5 Resep yang Paling Mirip (berdasarkan Ingredients dan Flavors Similarity):")
    for i, idx in enumerate(top_5_recipes.index):
        recipe = top_5_recipes.loc[idx]
        print(f"Rekomendasi #{i + 1}:")
        print(f"Title: {recipe['Title']}")
        print(f"Ingredients: {recipe['Ingredients']}")
        print(f"Steps: {recipe['Steps']}")
        print(f"Loves: {recipe['Loves']}")
        print(f"Similarity Score: {similarity_scores[idx]}")
        print("=" * 50)

# Meminta pengguna untuk memasukkan bahan
user_input_ingredients = input("Masukkan bahan makanan (pisahkan dengan koma): ")
user_ingredients = [ingredient.strip() for ingredient in user_input_ingredients.split(',')]

# Meminta pengguna untuk memasukkan rasa yang diinginkan
user_input_flavors = input("Masukkan rasa yang diinginkan (pisahkan dengan koma): ")
user_flavors = [flavor.strip() for flavor in user_input_flavors.split(',')]

# Memastikan bahwa setiap elemen dalam kolom 'Ingredients' dan 'Steps' bukan NaN
df['Ingredients'] = df['Ingredients'].apply(lambda x: '' if pd.isna(x) else x)
df['Steps'] = df['Steps'].apply(lambda x: '' if pd.isna(x) else x)

# Lakukan prediksi dengan bahan dan rasa yang dimasukkan pengguna
predict_top_5_recipes(user_ingredients, user_flavors, vectorizer, best_rf_model, df)

"""## COBA-COBA dibawah sini"""

from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

# ...

# Fungsi untuk melakukan prediksi 5 resep berdasarkan bahan dan rasa
def predict_top_5_recipes(ingredients, flavors, vectorizer, model, df):
    # Transformasi bahan dan rasa ke dalam format yang sama dengan data latih
    input_text = ' '.join(ingredients + flavors)
    input_vector = vectorizer.transform([input_text])

    # Lakukan prediksi
    prediction = model.predict(input_vector)[0]

    # Temukan resep dengan bahan paling mirip
    ingredient_vectors = vectorizer.transform(df['Ingredients'] + ' ' + df['Steps'])
    similarity_scores = cosine_similarity(input_vector, ingredient_vectors).flatten()

    # Berikan tambahan point untuk setiap resep yang mengandung rasa yang diinginkan
    for flavor in flavors:
        similarity_scores += df['Ingredients'].apply(lambda x: flavor.lower() in x.lower()).astype(int)

    # Temukan 5 resep paling mirip berdasarkan similarity
    top_5_indices = similarity_scores.argsort()[-5:][::-1]
    top_5_recipes = df.iloc[top_5_indices]

    # Tampilkan pertanyaan input
    print(f"Bahan yang Dimasukkan: {', '.join(ingredients)}")
    print(f"Rasa yang Diinginkan: {', '.join(flavors)}")

    # Tampilkan hasil
    print("Top 5 Resep yang Paling Mirip (berdasarkan Ingredients dan Flavors Similarity):")
    for i, idx in enumerate(top_5_recipes.index):
        recipe = top_5_recipes.loc[idx]
        print(f"Rekomendasi #{i + 1}:")
        print(f"Title: {recipe['Title']}")
        print(f"Ingredients: {recipe['Ingredients']}")
        print(f"Steps: {recipe['Steps']}")
        print(f"Loves: {recipe['Loves']}")
        print(f"Similarity Score: {similarity_scores[idx]}")
        print("=" * 50)

# Meminta pengguna untuk memasukkan bahan
user_input_ingredients = input("Masukkan bahan makanan (pisahkan dengan koma): ")
user_ingredients = [ingredient.strip() for ingredient in user_input_ingredients.split(',')]

# Menampilkan dropdown menu untuk rasa yang diinginkan
flavor_options = ["pedas", "asin", "gurih", "tidak pedas", "manis"]
print("Pilih rasa yang diinginkan:")
for i, flavor in enumerate(flavor_options, start=1):
    print(f"{i}. {flavor}")

# Meminta pengguna untuk memilih rasa
selected_flavor_index = int(input("Masukkan nomor rasa yang diinginkan: "))
user_flavors = [flavor_options[selected_flavor_index - 1]]

# Memastikan bahwa setiap elemen dalam kolom 'Ingredients' dan 'Steps' bukan NaN
df['Ingredients'] = df['Ingredients'].apply(lambda x: '' if pd.isna(x) else x)
df['Steps'] = df['Steps'].apply(lambda x: '' if pd.isna(x) else x)

# Lakukan prediksi dengan bahan dan rasa yang dimasukkan pengguna
predict_top_5_recipes(user_ingredients, user_flavors, vectorizer, best_rf_model, df)